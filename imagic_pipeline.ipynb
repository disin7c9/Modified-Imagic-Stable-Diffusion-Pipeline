{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486c5eb7-d8d3-4cfe-9a91-8b5290403db7",
   "metadata": {},
   "source": [
    "## 1 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e9d9c8-7801-4016-bcd6-a02ec1cbe260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), 'modules'))\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import (\n",
    "    AutoencoderKL, \n",
    "    UNet2DConditionModel, \n",
    "    # StableDiffusionPipeline,\n",
    "    EulerAncestralDiscreteScheduler\n",
    ")\n",
    "from transformers import CLIPTextModel, CLIPTokenizer#, CLIPImageProcessor\n",
    "from modified_imagic_stable_diffusion import ImagicStableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9b4fca-439d-4455-bfa1-c22fae32ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed1f47b-0ac5-4941-92d7-cb2b07a5cfc8",
   "metadata": {},
   "source": [
    "## 2 load checkpoints and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f003d2-1150-4472-987d-39983e1eb787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\miniconda3\\envs\\imagic\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sd_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "clip_path = \"openai/clip-vit-large-patch14\"\n",
    "\n",
    "# runwayml/stable-diffusion-v1-5\n",
    "vae = AutoencoderKL.from_pretrained(sd_path, subfolder=\"vae\")\n",
    "unet = UNet2DConditionModel.from_pretrained(sd_path, subfolder=\"unet\")\n",
    "scheduler = EulerAncestralDiscreteScheduler.from_pretrained(sd_path, subfolder=\"scheduler\")\n",
    "safety_checker = None\n",
    "# safety_checker = StableDiffusionPipeline.from_pretrained(sd_path, subfolder=\"safety_checker\")\n",
    "\n",
    "# openai/clip-vit-large-patch14\n",
    "tokenizer = CLIPTokenizer.from_pretrained(clip_path)\n",
    "text_encoder = CLIPTextModel.from_pretrained(clip_path)\n",
    "feature_extractor = None\n",
    "# feature_extractor = CLIPImageProcessor.from_pretrained(clip_path) # safety_checker => feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8646f9-30cd-491b-9484-51269e36d715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "vae = vae.to(device)\n",
    "text_encoder = text_encoder.to(device)\n",
    "unet = unet.to(device)\n",
    "\n",
    "pipeline = ImagicStableDiffusionPipeline(\n",
    "    vae=vae,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer,\n",
    "    unet=unet,\n",
    "    scheduler=scheduler,\n",
    "    safety_checker=safety_checker,\n",
    "    feature_extractor=feature_extractor\n",
    ")\n",
    "\n",
    "pipeline = pipeline.to(device)\n",
    "print(pipeline.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ed738-e656-47be-a120-eaf6c8c0129d",
   "metadata": {},
   "source": [
    "## optimize the target embedding and fine-tune the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7a51a-6afd-41b5-a635-d22bb7bae848",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cat wearing the Renaissance-style knight's helmet and full plate armour, with only its bare legs showing\"\n",
    "\n",
    "init_image = Image.open(\"./image_stocks/ginger_cat2.jpg\")\n",
    "guidance_scale = 13\n",
    "\n",
    "generator = torch.Generator(device).manual_seed(0)\n",
    "display(init_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0138459-4799-4fb6-9fd5-b70ef6dfefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.train(\n",
    "    prompt = prompt,\n",
    "    image = init_image,\n",
    "    guidance_scale = guidance_scale,\n",
    "    generator = generator,\n",
    "    height = 512,\n",
    "    width = 512,\n",
    "    embedding_learning_rate = 5e-4,\n",
    "    diffusion_model_learning_rate = 1e-7,\n",
    "    text_embedding_optimization_steps = 1000,\n",
    "    model_fine_tuning_optimization_steps = 1000,\n",
    "    show_progress = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee63ea6-8b8c-4ee8-a686-11120a989b8f",
   "metadata": {},
   "source": [
    "## call inference procedure from the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c2294-ee10-4345-9d8a-03a5f118bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_list:list, alpha_list:list, folder_name:str=\"outputs\", filename_prefix:str=\"generated_image\"):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    for i, image in enumerate(image_list):\n",
    "        filename = os.path.join(folder_name, f\"{filename_prefix}_alpha-{alpha_list[i]}.png\")\n",
    "        image.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0cd468-c015-43cd-98ef-b718150a53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "alphas = [0.0, 0.4, 0.6, 0.8, 1, 1.2, 1.4]\n",
    "for alpha in alphas:\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "    img = pipeline(\n",
    "        alpha = alpha,\n",
    "        height = 512,\n",
    "        width = 512,\n",
    "        guidance_scale = guidance_scale,\n",
    "        generator = generator,\n",
    "        init_timestep_rate = 0,\n",
    "        )\n",
    "    imgs.append(img.images[0])\n",
    "    print(f\"alpha: {alpha}\")\n",
    "    display(img.images[0])\n",
    "save_images(imgs, alphas, filename_prefix=\"Puss0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed803157-e77d-48bc-b287-8ccd1ad29467",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "alphas = [0.0, 0.4, 0.6, 0.8, 1, 1.2, 1.4]\n",
    "for alpha in alphas:\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "    img = pipeline(\n",
    "        alpha = alpha,\n",
    "        height = 512,\n",
    "        width = 512,\n",
    "        guidance_scale = guidance_scale,\n",
    "        generator = generator,\n",
    "        init_timestep_rate = 0.1,\n",
    "        )\n",
    "    imgs.append(img.images[0])\n",
    "    print(f\"alpha: {alpha}\")\n",
    "    display(img.images[0])\n",
    "save_images(imgs, alphas, filename_prefix=\"Puss0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769da73-b429-4000-8384-7996d0f35d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "alphas = [0.0, 0.4, 0.6, 0.8, 1, 1.2, 1.4]\n",
    "for alpha in alphas:\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "    img = pipeline(\n",
    "        alpha = alpha,\n",
    "        height = 512,\n",
    "        width = 512,\n",
    "        guidance_scale = guidance_scale,\n",
    "        generator = generator,\n",
    "        init_timestep_rate = 0.2,\n",
    "        )\n",
    "    imgs.append(img.images[0])\n",
    "    print(f\"alpha: {alpha}\")\n",
    "    display(img.images[0])\n",
    "save_images(imgs, alphas, filename_prefix=\"Puss0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b5b6b-bb08-4ef9-bee8-0d96a1feb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "alphas = [0.0, 0.4, 0.6, 0.8, 1, 1.2, 1.4]\n",
    "for alpha in alphas:\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "    img = pipeline(\n",
    "        alpha = alpha,\n",
    "        height = 512,\n",
    "        width = 512,\n",
    "        guidance_scale = guidance_scale,\n",
    "        generator = generator,\n",
    "        init_timestep_rate = 0.3,\n",
    "        )\n",
    "    imgs.append(img.images[0])\n",
    "    print(f\"alpha: {alpha}\")\n",
    "    display(img.images[0])\n",
    "save_images(imgs, alphas, filename_prefix=\"Puss0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9e25f-3e4d-4ef8-a054-7a4f02a156d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "alphas = [0.0, 0.4, 0.6, 0.8, 1, 1.2, 1.4]\n",
    "for alpha in alphas:\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "    img = pipeline(\n",
    "        alpha = alpha,\n",
    "        height = 512,\n",
    "        width = 512,\n",
    "        guidance_scale = guidance_scale,\n",
    "        generator = generator,\n",
    "        init_timestep_rate = 0.4,\n",
    "        )\n",
    "    imgs.append(img.images[0])\n",
    "    print(f\"alpha: {alpha}\")\n",
    "    display(img.images[0])\n",
    "save_images(imgs, alphas, filename_prefix=\"Puss0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a4f1d-c78a-446d-8720-5296939b354e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
